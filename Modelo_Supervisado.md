## Predicci√≥n de Mora (Modelo Supervisado)

Este an√°lisis tiene como objetivo predecir la probabilidad de que un cliente incurra en mora utilizando algoritmos de clasificaci√≥n.

---

### üîπ 1. Preprocesamiento de variables

Se aplicaron filtros previos para reducir dimensionalidad:

- **Eliminaci√≥n de baja varianza** (`threshold=0.01`)
- **Eliminaci√≥n de variables altamente correlacionadas** (`r > 0.9`)
- **Selecci√≥n de las 20 mejores variables** usando `SelectKBest` con estad√≠stico ANOVA F (`f_classif`)

---

### üîπ 2. Separaci√≥n de datos

El conjunto de datos fue separado en:

- `X`: variables predictoras
- `y`: variable objetivo (`TARGET`)
- Divisi√≥n en `train` y `test` (75/25, estratificada)

Se aplic√≥ `StandardScaler` para estandarizar los datos antes del entrenamiento.

---
### üîπ 3. Modelos comparativos iniciales

Antes de aplicar LightGBM, se evaluaron dos modelos de clasificaci√≥n cl√°sicos: **Regresi√≥n Log√≠stica** y **Random Forest**. Ambos se entrenaron con el conjunto balanceado y las 20 variables seleccionadas previamente.

#### üìà Resultados de Regresi√≥n Log√≠stica

- Buen desempe√±o identificando la clase minoritaria (clientes morosos).
- Recall de 0.67 en la clase 1, aunque con precisi√≥n limitada.
- AUC competitivo, superior a 0.73.

```
Logistic Regression
              precision    recall  f1-score   support

         0.0       0.96      0.68      0.80     70672
         1.0       0.16      0.67      0.25      6206

    accuracy                           0.68     76878
   macro avg       0.56      0.68      0.53     76878
weighted avg       0.89      0.68      0.75     76878

AUC: 0.7377
```

#### üå≤ Resultados de Random Forest

- Alta precisi√≥n en clase 0, pero recall muy bajo en la clase 1.
- El modelo pr√°cticamente no identifica clientes morosos.
- AUC inferior al de regresi√≥n log√≠stica.

```
Random Forest
              precision    recall  f1-score   support

         0.0       0.92      1.00      0.96     70672
         1.0       0.57      0.00      0.01      6206

    accuracy                           0.92     76878
   macro avg       0.74      0.50      0.48     76878
weighted avg       0.89      0.92      0.88     76878

AUC: 0.7199
```

### ‚úÖ Conclusi√≥n preliminar

Aunque ambos modelos fueron √∫tiles como referencia, se opt√≥ por avanzar con **LightGBM** debido a que logr√≥ un mejor equilibrio entre precisi√≥n y recall, adem√°s de mantener un AUC superior. En la siguiente secci√≥n se describe su configuraci√≥n y optimizaci√≥n.

### üîπ 4. Modelado con LightGBM

Se utiliz√≥ el clasificador `LGBMClassifier`, configurado para manejar desbalance con:

- `scale_pos_weight = ratio_entre_clases`

Se realiz√≥ ajuste de hiperpar√°metros usando `RandomizedSearchCV` con validaci√≥n cruzada (CV=3) y 30 combinaciones aleatorias.

Par√°metros optimizados:
- `num_leaves`
- `learning_rate`
- `max_depth`
- `n_estimators`
- `min_child_samples`
- `subsample`
- `colsample_bytree`

---

### üîπ 5. M√©tricas de Evaluaci√≥n

Se utilizaron las siguientes m√©tricas sobre el conjunto de prueba para evaluar el desempe√±o del modelo:

- **Precision, Recall y F1-score** de ambas clases (`0`: no moroso, `1`: moroso)
- **AUC (√Årea bajo la curva ROC)** como m√©trica principal para evaluar capacidad discriminativa

#### üìä Resultados obtenidos con LightGBM

El modelo logr√≥ mejorar respecto a los modelos anteriores, en especial en la clase minoritaria (`1`), con un recall elevado y AUC competitivo:

```
LightGBM
              precision    recall  f1-score   support

         0.0       0.96      0.68      0.80     70672
         1.0       0.16      0.68      0.26      6206

    accuracy                           0.68     76878
   macro avg       0.56      0.68      0.53     76878
weighted avg       0.90      0.68      0.75     76878

AUC: 0.7465
```

El modelo mostr√≥ un balance razonable al identificar clientes con riesgo de mora, mejorando la capacidad de detecci√≥n sin sacrificar excesivamente la precisi√≥n.

---

### üîπ 6. Interpretaci√≥n de resultados

El modelo LightGBM optimizado logr√≥ resultados **comparables y superiores** a los modelos base (Regresi√≥n Log√≠stica y Random Forest), especialmente en la **detecci√≥n de morosos** (clase 1), lo cual es crucial en un sistema de gesti√≥n de riesgo financiero.

#### üìå Evaluaci√≥n de efectividad

- **Recall (0.68) en la clase 1** indica que el modelo identifica aproximadamente el **68% de los clientes que efectivamente caer√°n en mora**. Esto es una mejora sustancial frente a Random Forest (recall ~0).
- **Precisi√≥n (0.16)** Una precisi√≥n del 16% en la clase de morosos implica que, aunque el modelo logra identificar a la mayor√≠a de los clientes que realmente caer√°n en mora (recall alto), tambi√©n genera una cantidad considerable de falsos positivos. En un contexto real, esto puede traducirse en decisiones conservadoras: limitar o condicionar el cr√©dito a clientes que en realidad habr√≠an pagado. No obstante, esta estrategia puede ser √∫til para prevenir p√©rdidas si se implementa como un sistema de alerta temprana, especialmente si se complementa con an√°lisis adicionales o ajustes en el umbral de decisi√≥n.
- **AUC (0.746)** confirma que el modelo tiene una **buena capacidad de discriminaci√≥n global**, distinguiendo entre clientes en riesgo y no en riesgo con un √°rea bajo la curva ROC del 74.6%.

En resumen, el modelo es **exitoso en su prop√≥sito principal: detectar posibles morosos con buena cobertura**, aunque sacrificando algo de precisi√≥n debido al desbalance de clases. Para un sistema real, este comportamiento es aceptable si el objetivo es **minimizar el riesgo crediticio a trav√©s de medidas preventivas**.

---

### üìä Importancia de las variables

El gr√°fico siguiente muestra las 20 variables m√°s influyentes en el modelo LightGBM, basadas en su ganancia acumulada en la construcci√≥n de √°rboles:

![Importancia de variables - LightGBM](images/importance_lbgm.png)

#### üß† An√°lisis de variables clave

- Las variables m√°s importantes provienen de:
  - **Scores externos** (`EXT_SOURCE_1`, `EXT_SOURCE_2`, `EXT_SOURCE_3`)
  - **Edad (`DAYS_BIRTH`)** y **antig√ºedad laboral (`DAYS_EMPLOYED`)**
  - **Historial de cr√©dito en bur√≥** (`BUREAU_*`)
- Esto confirma que el **riesgo crediticio se explica mejor por fuentes externas y comportamientos hist√≥ricos**, m√°s que por variables socioecon√≥micas superficiales.

Adem√°s, variables como `CODE_GENDER_F`, `EDUCATION_TYPE` y `REGION_RATING_CLIENT` tambi√©n aparecen en el top, indicando que **ciertas caracter√≠sticas demogr√°ficas tienen un impacto no despreciable**.

El modelo aprovecha estas variables para construir √°rboles de decisi√≥n eficientes que diferencian perfiles de bajo y alto riesgo.

---
### üîπ 7. Conclusi√≥n

El modelo final puede ser usado como base para priorizar evaluaci√≥n de riesgo, con posibilidad de ser mejorado v√≠a:

- Ajuste de umbrales
- T√©cnicas de remuestreo (SMOTE)
- Modelos m√°s complejos (XGBoost)
