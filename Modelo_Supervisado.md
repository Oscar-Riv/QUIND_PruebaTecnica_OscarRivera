## Predicci贸n de Mora (Modelo Supervisado)

Este an谩lisis tiene como objetivo predecir la probabilidad de que un cliente incurra en mora utilizando algoritmos de clasificaci贸n.

---

###  1. Preprocesamiento de variables

Se aplicaron filtros previos para reducir dimensionalidad:

- **Eliminaci贸n de baja varianza** (`threshold=0.01`)
- **Eliminaci贸n de variables altamente correlacionadas** (`r > 0.9`)
- **Selecci贸n de las 20 mejores variables** usando `SelectKBest` con estad铆stico ANOVA F (`f_classif`)

---

###  2. Separaci贸n de datos

El conjunto de datos fue separado en:

- `X`: variables predictoras
- `y`: variable objetivo (`TARGET`)
- Divisi贸n en `train` y `test` (75/25, estratificada)

Se aplic贸 `StandardScaler` para estandarizar los datos antes del entrenamiento.

---

###  3. Modelado con LightGBM

Se utiliz贸 el clasificador `LGBMClassifier`, configurado para manejar desbalance con:

- `scale_pos_weight = ratio_entre_clases`

Se realiz贸 ajuste de hiperpar谩metros usando `RandomizedSearchCV` con validaci贸n cruzada (CV=3) y 30 combinaciones aleatorias.

Par谩metros optimizados:
- `num_leaves`
- `learning_rate`
- `max_depth`
- `n_estimators`
- `min_child_samples`
- `subsample`
- `colsample_bytree`

---

###  4. M茅tricas de Evaluaci贸n

Se utilizaron las siguientes m茅tricas sobre el conjunto de prueba:

- **Precision, Recall y F1-score** de ambas clases (moroso / no moroso)
- **AUC (rea bajo la curva ROC)** para evaluar capacidad discriminativa

---

###  5. Interpretaci贸n de resultados

- El modelo LightGBM optimizado obtuvo mejor desempe帽o que la regresi贸n log铆stica y random forest en AUC y F1-score.
- Se identificaron las variables m谩s importantes para la predicci贸n (visualizadas con un gr谩fico de barras).
- A pesar de no alcanzar precisi贸n perfecta, el modelo logra un **buen balance entre identificar morosos y minimizar falsos positivos**.

---

###  6. Conclusi贸n

El modelo final puede ser usado como base para priorizar evaluaci贸n de riesgo, con posibilidad de ser mejorado v铆a:

- Ajuste de umbrales
- T茅cnicas de remuestreo (SMOTE)
- Modelos m谩s complejos (XGBoost)
